version: "3.9"

services:
  backend:
    image: vectorpathconsulting/multiagent-qna-backend:latest
    container_name: multiagent-qna-backend
    environment:
      # Direct API mode
      BASE_URL: "https://inference-on-ibm.edgecollaborate.com"
      INFERENCE_API_KEY: "replace-with-your-key"

      # Model endpoints on your gateway
      EMBEDDING_MODEL_ENDPOINT: "bge-base-en-v1.5"
      INFERENCE_MODEL_ENDPOINT: "Llama-3.1-8B-Instruct"
      EMBEDDING_MODEL_NAME: "bge-base-en-v1.5"
      INFERENCE_MODEL_NAME: "meta-llama/Llama-3.1-8B-Instruct"

      # Optional Keycloak path (only used if all three set)
      KEYCLOAK_CLIENT_ID: ""
      KEYCLOAK_CLIENT_SECRET: ""
      KEYCLOAK_REALM: "master"
    ports:
      - "8002:5001"
    networks:
      - appnet
    restart: unless-stopped

  frontend:
    image: vectorpathconsulting/multiagent-qna-frontend:latest
    container_name: multiagent-qna-frontend
    depends_on:
      - backend
    ports:
      - "8082:80"
    networks:
      - appnet
    restart: unless-stopped

  info:
    image: alpine:latest
    container_name: multiagent-qna-info
    command: >
      sh -c "
      echo '';
      echo '==============================================';
      echo '  Inference Blueprint: Multi-Agent Q&A';
      echo '----------------------------------------------';
      echo ' Open your browser to: http://localhost:8082';
      echo '==============================================';
      echo '';
      sleep 10;
      "
    networks:
      - appnet

networks:
  appnet:
    driver: bridge

